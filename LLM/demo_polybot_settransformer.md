æˆ‘å°†åŸºäºè®ºæ–‡æè¿°å’ŒSet-Transformeræ¶æ„ï¼Œå®Œæ•´å®ç°ä¸€ä¸ªå¯ä»¥å¤„ç†å…±èšç‰©ã€é¢„æµ‹ä¸ç¡®å®šæ€§å¹¶æ¥å…¥è‡ªåŠ¨åŒ–å·¥ä½œæµçš„é¢„æµ‹æ¨¡å‹ã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import List, Dict, Tuple, Optional
import json
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
import warnings
warnings.filterwarnings('ignore')

# Set-Transformer æ ¸å¿ƒæ¨¡å— (åŸºäºå®˜æ–¹å®ç°)
class MAB(nn.Module):
    def __init__(self, dim_Q, dim_K, dim_V, num_heads, ln=False):
        super(MAB, self).__init__()
        self.dim_V = dim_V
        self.num_heads = num_heads
        self.fc_q = nn.Linear(dim_Q, dim_V)
        self.fc_k = nn.Linear(dim_K, dim_V)
        self.fc_v = nn.Linear(dim_K, dim_V)
        if ln:
            self.ln0 = nn.LayerNorm(dim_V)
            self.ln1 = nn.LayerNorm(dim_V)
        self.fc_o = nn.Linear(dim_V, dim_V)

    def forward(self, Q, K):
        Q = self.fc_q(Q)
        K, V = self.fc_k(K), self.fc_v(K)

        dim_split = self.dim_V // self.num_heads
        Q_ = torch.cat(Q.split(dim_split, 2), 0)
        K_ = torch.cat(K.split(dim_split, 2), 0)
        V_ = torch.cat(V.split(dim_split, 2), 0)

        A = torch.softmax(Q_.bmm(K_.transpose(1,2))/np.sqrt(self.dim_V), 2)
        O = torch.cat((Q_ + A.bmm(V_)).split(Q.size(0), 0), 2)
        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)
        O = O + F.relu(self.fc_o(O))
        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)
        return O

class SAB(nn.Module):
    def __init__(self, dim_in, dim_out, num_heads, ln=False):
        super(SAB, self).__init__()
        self.mab = MAB(dim_in, dim_in, dim_out, num_heads, ln=ln)

    def forward(self, X):
        return self.mab(X, X)

class ISAB(nn.Module):
    def __init__(self, dim_in, dim_out, num_heads, num_inds, ln=False):
        super(ISAB, self).__init__()
        self.I = nn.Parameter(torch.Tensor(1, num_inds, dim_out))
        nn.init.xavier_uniform_(self.I)
        self.mab0 = MAB(dim_out, dim_in, dim_out, num_heads, ln=ln)
        self.mab1 = MAB(dim_in, dim_out, dim_out, num_heads, ln=ln)

    def forward(self, X):
        H = self.mab0(self.I.repeat(X.size(0), 1, 1), X)
        return self.mab1(X, H)

class PMA(nn.Module):
    def __init__(self, dim, num_heads, num_seeds, ln=False):
        super(PMA, self).__init__()
        self.S = nn.Parameter(torch.Tensor(1, num_seeds, dim))
        nn.init.xavier_uniform_(self.S)
        self.mab = MAB(dim, dim, dim, num_heads, ln=ln)

    def forward(self, X):
        return self.mab(self.S.repeat(X.size(0), 1, 1), X)

class SetTransformer(nn.Module):
    def __init__(self, dim_input, dim_output, num_inds=32, dim_hidden=128, num_heads=4, ln=False):
        super(SetTransformer, self).__init__()
        self.enc = nn.Sequential(
            ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),
            ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln)
        )
        self.dec = nn.Sequential(
            PMA(dim_hidden, num_heads, 1, ln=ln),
            nn.Linear(dim_hidden, dim_output)
        )

    def forward(self, X):
        return self.dec(self.enc(X)).squeeze(-1)

# å…±èšç‰©é¢„æµ‹æ¨¡å‹ (åŒè§£ç å™¨ + ä¸ç¡®å®šæ€§ä¼°è®¡)
class CopolymerPredictor(nn.Module):
    def __init__(self, monomer_feature_dim=512, color_dim=3, spectrum_dim=300, 
                 num_inds=32, dim_hidden=256, num_heads=8, dropout_rate=0.1):
        super(CopolymerPredictor, self).__init__()
        
        # ç¼–ç å™¨ - å¤„ç†å…±èšç‰©å•ä½“é›†åˆ
        self.encoder = SetTransformer(
            dim_input=monomer_feature_dim + 1,  # +1 for ratio
            dim_output=dim_hidden,
            num_inds=num_inds,
            dim_hidden=dim_hidden,
            num_heads=num_heads,
            ln=True
        )
        
        # é¢œè‰²è§£ç å™¨ - é¢„æµ‹ L*a*b* å€¼
        self.color_decoder = nn.Sequential(
            nn.Linear(dim_hidden, 128),
            nn.Dropout(dropout_rate),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.Dropout(dropout_rate),
            nn.ReLU(),
            nn.Linear(64, color_dim)  # L*, a*, b*
        )
        
        # å…‰è°±è§£ç å™¨ - é¢„æµ‹å¸æ”¶å…‰è°±
        self.spectrum_decoder = nn.Sequential(
            nn.Linear(dim_hidden, 128),
            nn.Dropout(dropout_rate),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.Dropout(dropout_rate),
            nn.ReLU(),
            nn.Linear(256, spectrum_dim)  # 300-point spectrum
        )
        
        self.dropout_rate = dropout_rate
        
    def forward(self, monomer_sets, mc_dropout=False):
        """
        Args:
            monomer_sets: List of tensors [batch_size, num_monomers, feature_dim+1]
            mc_dropout: Whether to use MC dropout for uncertainty estimation
        """
        # ç¼–ç å…±èšç‰©
        encoded = self.encoder(monomer_sets)
        
        # åº”ç”¨MC Dropoutå¦‚æœå¯ç”¨
        if mc_dropout:
            encoded = F.dropout(encoded, p=self.dropout_rate, training=True)
        
        # åŒè§£ç 
        color_pred = self.color_decoder(encoded)
        spectrum_pred = self.spectrum_decoder(encoded)
        
        return color_pred, spectrum_pred
    
    def predict_with_uncertainty(self, monomer_sets, num_samples=50):
        """ä½¿ç”¨MC Dropoutè¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡"""
        color_predictions = []
        spectrum_predictions = []
        
        self.train()  # ä¿æŒtrainæ¨¡å¼ä»¥å¯ç”¨dropout
        
        with torch.no_grad():
            for _ in range(num_samples):
                color_pred, spectrum_pred = self.forward(monomer_sets, mc_dropout=True)
                color_predictions.append(color_pred.cpu().numpy())
                spectrum_predictions.append(spectrum_pred.cpu().numpy())
        
        color_predictions = np.array(color_predictions)
        spectrum_predictions = np.array(spectrum_predictions)
        
        color_mean = color_predictions.mean(axis=0)
        color_std = color_predictions.std(axis=0)
        spectrum_mean = spectrum_predictions.mean(axis=0)
        spectrum_std = spectrum_predictions.std(axis=0)
        
        return color_mean, color_std, spectrum_mean, spectrum_std

# åˆ†å­ç‰¹å¾æå–å™¨
class MolecularFeatureExtractor:
    def __init__(self, fingerprint_size=2048, radius=3):
        self.fingerprint_size = fingerprint_size
        self.radius = radius
        
    def smiles_to_fingerprint(self, smiles):
        """å°†SMILESè½¬æ¢ä¸ºMorganæŒ‡çº¹"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                return np.zeros(self.fingerprint_size)
            fingerprint = AllChem.GetMorganFingerprintAsBitVect(
                mol, radius=self.radius, nBits=self.fingerprint_size
            )
            return np.array(fingerprint)
        except:
            return np.zeros(self.fingerprint_size)
    
    def prepare_copolymer_input(self, monomers_dict):
        """
        å‡†å¤‡å…±èšç‰©è¾“å…¥
        Args:
            monomers_dict: {'SMILES1': ratio1, 'SMILES2': ratio2, ...}
        """
        features = []
        ratios = []
        
        for smiles, ratio in monomers_dict.items():
            fp = self.smiles_to_fingerprint(smiles)
            features.append(fp)
            ratios.append(ratio)
        
        # å½’ä¸€åŒ–æ¯”ä¾‹
        ratios = np.array(ratios) / sum(ratios)
        
        # åˆå¹¶ç‰¹å¾å’Œæ¯”ä¾‹
        combined_features = []
        for i in range(len(features)):
            combined = np.concatenate([features[i], [ratios[i]]])
            combined_features.append(combined)
        
        return np.array(combined_features)

# è‡ªåŠ¨åŒ–å·¥ä½œæµé›†æˆå™¨
class AutonomousWorkflowManager:
    def __init__(self, model, feature_extractor, target_color, available_monomers):
        self.model = model
        self.feature_extractor = feature_extractor
        self.target_color = torch.tensor(target_color, dtype=torch.float32)  # [L*, a*, b*]
        self.available_monomers = available_monomers
        self.database = []
        self.iteration_count = 0
        
    def calculate_color_difference(self, predicted_color):
        """è®¡ç®—Î”E Labé¢œè‰²å·®å¼‚"""
        return torch.sqrt(torch.sum((predicted_color - self.target_color) ** 2)).item()
    
    def expected_improvement(self, predicted_color, uncertainty, best_deltaE):
        """æœŸæœ›æ”¹è¿›é‡‡é›†å‡½æ•°"""
        deltaE = self.calculate_color_difference(predicted_color)
        improvement = best_deltaE - deltaE
        z = improvement / (uncertainty + 1e-8)
        ei = improvement * torch.special.erf(z) + uncertainty * torch.exp(-0.5 * z**2) / np.sqrt(2 * np.pi)
        return ei.item()
    
    def select_next_candidates(self, num_candidates=6):
        """é€‰æ‹©ä¸‹ä¸€æ‰¹å®éªŒå€™é€‰"""
        if not self.database:
            # ç¬¬ä¸€è½®ï¼šéšæœºé€‰æ‹©
            candidates = []
            for _ in range(num_candidates):
                num_mers = np.random.choice([2, 3])  # 2æˆ–3ä¸ªå•ä½“
                selected_mers = np.random.choice(
                    list(self.available_monomers.keys()), 
                    num_mers, 
                    replace=False
                )
                ratios = np.random.dirichlet(np.ones(num_mers))
                candidate = {mer: ratio for mer, ratio in zip(selected_mers, ratios)}
                candidates.append(candidate)
            return candidates
        
        # åŸºäºEIé€‰æ‹©å€™é€‰
        best_deltaE = min([exp['deltaE'] for exp in self.database])
        candidates = []
        eis = []
        
        # ç”Ÿæˆå€™é€‰å¹¶è¯„ä¼°
        for _ in range(100):  # ç”Ÿæˆå¤§é‡å€™é€‰è¿›è¡Œç­›é€‰
            num_mers = np.random.choice([2, 3])
            selected_mers = np.random.choice(
                list(self.available_monomers.keys()), 
                num_mers, 
                replace=False
            )
            ratios = np.random.dirichlet(np.ones(num_mers))
            candidate_dict = {mer: ratio for mer, ratio in zip(selected_mers, ratios)}
            
            # é¢„æµ‹é¢œè‰²å’Œä¸ç¡®å®šæ€§
            features = self.feature_extractor.prepare_copolymer_input(candidate_dict)
            features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)
            
            color_mean, color_std, _, _ = self.model.predict_with_uncertainty(features_tensor)
            predicted_color = torch.tensor(color_mean[0])
            uncertainty = torch.tensor(color_std[0].mean())
            
            ei = self.expected_improvement(predicted_color, uncertainty, best_deltaE)
            
            candidates.append(candidate_dict)
            eis.append(ei)
        
        # é€‰æ‹©EIæœ€é«˜çš„å€™é€‰
        top_indices = np.argsort(eis)[-num_candidates:]
        return [candidates[i] for i in top_indices]
    
    def run_iteration(self, experimental_results=None):
        """è¿è¡Œä¸€æ¬¡è¿­ä»£"""
        self.iteration_count += 1
        print(f"=== Iteration {self.iteration_count} ===")
        
        # é€‰æ‹©å€™é€‰
        candidates = self.select_next_candidates()
        print(f"Selected {len(candidates)} candidates")
        
        if experimental_results is None:
            # æ¨¡æ‹Ÿå®éªŒé˜¶æ®µ - åœ¨å®é™…ç³»ç»Ÿä¸­è¿™é‡Œä¼šè°ƒç”¨æœºå™¨äººæ‰§è¡Œå®éªŒ
            experimental_results = []
            for i, candidate in enumerate(candidates):
                # æ¨¡æ‹Ÿå®éªŒæµ‹é‡
                features = self.feature_extractor.prepare_copolymer_input(candidate)
                features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(0)
                color_mean, _, spectrum_mean, _ = self.model.predict_with_uncertainty(features_tensor)
                
                # æ·»åŠ ä¸€äº›å™ªå£°æ¨¡æ‹Ÿå®éªŒè¯¯å·®
                noise = np.random.normal(0, 0.5, 3)
                measured_color = color_mean[0] + noise
                deltaE = self.calculate_color_difference(torch.tensor(measured_color))
                
                result = {
                    'candidate': candidate,
                    'measured_color': measured_color.tolist(),
                    'measured_spectrum': spectrum_mean[0].tolist(),
                    'deltaE': deltaE
                }
                experimental_results.append(result)
                print(f"Candidate {i+1}: Î”E = {deltaE:.2f}")
        
        # æ›´æ–°æ•°æ®åº“
        self.database.extend(experimental_results)
        
        # é‡æ–°è®­ç»ƒæ¨¡å‹ (ç®€åŒ–ç‰ˆ - å®é™…ä¸­éœ€è¦å®Œæ•´è®­ç»ƒ)
        # self.retrain_model()
        
        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        best_deltaE = min([exp['deltaE'] for exp in experimental_results])
        print(f"Best Î”E in this iteration: {best_deltaE:.2f}")
        
        if best_deltaE < 3.0 or self.iteration_count >= 3:
            print("Optimization completed!")
            return True, experimental_results
        
        return False, experimental_results

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def main():
    # åˆå§‹åŒ–ç»„ä»¶
    feature_extractor = MolecularFeatureExtractor()
    model = CopolymerPredictor(
        monomer_feature_dim=2049,  # 2048-bit fingerprint + 1 ratio
        color_dim=3,
        spectrum_dim=300
    )
    
    # å®šä¹‰å¯ç”¨å•ä½“ (ç¤ºä¾‹)
    available_monomers = {
        'c1ccc(-c2ccccc2)cc1': 'Biphenyl',  # è”è‹¯
        'c1ccc(-c2ccsc2)cc1': 'Phenylthiophene',  # è‹¯åŸºå™»å©
        'c1ccsc1': 'Thiophene',  # å™»å©
        'c1ccc(-c2cccc(-c3ccccc3)c2)cc1': 'Terphenyl',  # ä¸‰è”è‹¯
        'c1cncc(-c2ccccc2)c1': 'Phenylpyridine'  # è‹¯åŸºå¡å•¶
    }
    
    # ç›®æ ‡é¢œè‰² (L*, a*, b*)
    target_color = [65, -10, 30]  # ç»¿è‰²
    
    # åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨
    workflow = AutonomousWorkflowManager(
        model=model,
        feature_extractor=feature_extractor,
        target_color=target_color,
        available_monomers=available_monomers
    )
    
    # è¿è¡Œä¼˜åŒ–å¾ªç¯
    for iteration in range(3):
        completed, results = workflow.run_iteration()
        if completed:
            break
    
    # è¾“å‡ºæœ€ä½³ç»“æœ
    best_result = min(workflow.database, key=lambda x: x['deltaE'])
    print(f"\nğŸ¯ Best candidate: Î”E = {best_result['deltaE']:.2f}")
    print(f"Color: {best_result['measured_color']}")
    print(f"Composition: {best_result['candidate']}")

if __name__ == "__main__":
    main()
```

è¿™ä¸ªå®ç°åŒ…å«ä»¥ä¸‹å…³é”®ç‰¹æ€§ï¼š

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

1. **å…±èšç‰©å¤„ç†**ï¼š
   - ä½¿ç”¨Set-Transformerå¤„ç†å¯å˜æ•°é‡çš„å•ä½“è¾“å…¥
   - æ”¯æŒ2-3ä¸ªå•ä½“çš„å…±èšç‰©ç»„åˆ
   - è€ƒè™‘å•ä½“æ¯”ä¾‹ä½œä¸ºè¾“å…¥ç‰¹å¾

2. **ä¸ç¡®å®šæ€§é¢„æµ‹**ï¼š
   - å®ç°MC Dropoutè¿›è¡Œä¸ç¡®å®šæ€§ä¼°è®¡
   - æä¾›é¢œè‰²å’Œå…‰è°±é¢„æµ‹çš„å‡å€¼å’Œæ ‡å‡†å·®

3. **è‡ªåŠ¨åŒ–å·¥ä½œæµé›†æˆ**ï¼š
   - åŸºäºæœŸæœ›æ”¹è¿›(EI)çš„å€™é€‰é€‰æ‹©
   - è¿­ä»£ä¼˜åŒ–å¾ªç¯
   - è‡ªåŠ¨ç»ˆæ­¢æ¡ä»¶ï¼ˆÎ”E < 3.0 æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼‰

## ğŸ”§ æ‰©å±•å»ºè®®

è¦æ¥å…¥çœŸå®çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼Œè¿˜éœ€è¦ï¼š

```python
# æœºå™¨äººæ§åˆ¶æ¥å£ (ç¤ºä¾‹)
class RobotController:
    def __init__(self, chemspeed_ip, tecan_ip, ur5e_ip):
        self.chemspeed_ip = chemspeed_ip
        self.tecan_ip = tecan_ip
        self.ur5e_ip = ur5e_ip
    
    def execute_synthesis(self, candidate):
        """è°ƒç”¨Chemspeedæ‰§è¡Œåˆæˆ"""
        # å®ç°å…·ä½“çš„æœºå™¨äººæ§åˆ¶é€»è¾‘
        pass
    
    def perform_characterization(self, sample_id):
        """è°ƒç”¨Tecanè¿›è¡ŒUV-Visè¡¨å¾"""
        pass
    
    def transfer_sample(self, from_station, to_station):
        """è°ƒç”¨UR5eæœºæ¢°è‡‚è½¬ç§»æ ·å“"""
        pass

# æ•°æ®åº“é›†æˆ
class ECPDatabase:
    def __init__(self, db_url):
        self.connection = create_engine(db_url)
    
    def store_experiment(self, candidate, results):
        """å­˜å‚¨å®éªŒæ•°æ®"""
        pass
    
    def get_training_data(self):
        """è·å–è®­ç»ƒæ•°æ®"""
        pass
```

è¿™ä¸ªå®ç°æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ¡†æ¶ï¼Œå¯ä»¥å¤„ç†è®ºæ–‡ä¸­æè¿°çš„å…±èšç‰©é¢„æµ‹ä»»åŠ¡ï¼Œå¹¶èƒ½å¤Ÿé›†æˆåˆ°è‡ªåŠ¨åŒ–å®éªŒå®¤å·¥ä½œæµä¸­å½¢æˆé—­ç¯ä¼˜åŒ–ã€‚
