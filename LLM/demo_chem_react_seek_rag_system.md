ç”±äºå®Œæ•´çš„ChemReactSeekç³»ç»Ÿæ¶‰åŠå¤šä¸ªå¤æ‚æ¨¡å—ï¼Œæˆ‘å°†æä¾›ä¸€ä¸ªç®€åŒ–çš„å®ç°æ¡†æ¶ï¼ŒåŒ…å«æ ¸å¿ƒåŠŸèƒ½çš„ä¸»è¦ä»£ç ç»“æ„ï¼š

```python
import faiss
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import SentenceTransformer
import fitz  # PyMuPDF
import json
from typing import List, Dict, Any
import openai

class ChemReactSeek:
    def __init__(self, knowledge_base_path: str, model_name: str = "deepseek-ai/deepseek-llm-7b-chat"):
        """
        åˆå§‹åŒ–ChemReactSeekç³»ç»Ÿ
        
        Args:
            knowledge_base_path: çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
            model_name: ä½¿ç”¨çš„LLMæ¨¡å‹åç§°
        """
        self.knowledge_base = self.load_knowledge_base(knowledge_base_path)
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.llm_tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.llm_model = AutoModel.from_pretrained(model_name)
        self.faiss_index = None
        self.text_corpus = []
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self._build_vector_database()
    
    def load_knowledge_base(self, file_path: str) -> List[Dict]:
        """åŠ è½½åŒ–å­¦çŸ¥è¯†åº“"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print("çŸ¥è¯†åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºç©ºçŸ¥è¯†åº“")
            return []
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬"""
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        return text
    
    def structured_data_extraction(self, text: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–åŒ–å­¦ååº”æ•°æ®
        """
        prompt = f"""
        è¯·ä»ä»¥ä¸‹åŒ–å­¦æ–‡çŒ®æ–‡æœ¬ä¸­æå–ååº”ä¿¡æ¯ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡ºï¼š
        
        æ–‡æœ¬ï¼š
        {text}
        
        è¯·æä¾›æå–çš„æ•°æ®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        Title:
        Summary:
        Chemical Reaction:
        Experimental Conditions:
        Reagents:
        Solvent:
        Catalyst:
        Type of catalyst:
        Catalyst usage details:
        Pressure Range:
        Reaction Temperature:
        Reaction Time:
        pH Value:
        Specific Values:
        Yield Procedure:
        Expected Yield:
        Procedure: 1. 2. 3.
        Notes:
        """
        
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è°ƒç”¨DeepSeek-v3 API
        extracted_data = self._call_llm_api(prompt)
        return self._parse_extracted_data(extracted_data)
    
    def _build_vector_database(self):
        """æ„å»ºFAISSå‘é‡æ•°æ®åº“"""
        if not self.knowledge_base:
            print("çŸ¥è¯†åº“ä¸ºç©ºï¼Œæ— æ³•æ„å»ºå‘é‡æ•°æ®åº“")
            return
        
        # å‡†å¤‡æ–‡æœ¬è¯­æ–™
        self.text_corpus = []
        for item in self.knowledge_base:
            text_representation = f"""
            Title: {item.get('title', '')}
            Summary: {item.get('summary', '')}
            Reaction: {item.get('chemical_reaction', '')}
            Conditions: {item.get('experimental_conditions', '')}
            Catalyst: {item.get('catalyst', '')}
            Solvent: {item.get('solvent', '')}
            """
            self.text_corpus.append(text_representation)
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        embeddings = self.embedding_model.encode(self.text_corpus)
        
        # åˆ›å»ºFAISSç´¢å¼•
        dimension = embeddings.shape[1]
        self.faiss_index = faiss.IndexFlatIP(dimension)  # ä½¿ç”¨å†…ç§¯ç›¸ä¼¼åº¦
        
        # å½’ä¸€åŒ–å‘é‡ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦
        faiss.normalize_L2(embeddings)
        self.faiss_index.add(embeddings)
        
        print(f"å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼ŒåŒ…å« {len(self.text_corpus)} ä¸ªæ–‡æ¡£")
    
    def semantic_search(self, query: str, k: int = 5) -> List[Dict]:
        """
        è¯­ä¹‰æœç´¢ç›¸å…³ååº”ä¿¡æ¯
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›æœ€ç›¸å…³çš„kä¸ªç»“æœ
        """
        if self.faiss_index is None:
            return []
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        # æœç´¢ç›¸ä¼¼æ–‡æ¡£
        similarities, indices = self.faiss_index.search(query_embedding, k)
        
        results = []
        for i, idx in enumerate(indices[0]):
            if idx < len(self.knowledge_base):
                result = self.knowledge_base[idx].copy()
                result['similarity_score'] = float(similarities[0][i])
                results.append(result)
        
        return results
    
    def generate_reaction_protocol(self, query: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆååº”å®éªŒæ–¹æ¡ˆ
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢ï¼Œå¦‚"è®¾è®¡HMFæ°¢åŒ–ååº”çš„å®éªŒæ–¹æ¡ˆ"
        """
        # 1. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        retrieved_info = self.semantic_search(query)
        
        # 2. æ„å»ºå¢å¼ºæç¤º
        context = self._build_rag_context(retrieved_info)
        
        # 3. ç”Ÿæˆååº”æ–¹æ¡ˆ
        prompt = self._construct_protocol_prompt(query, context)
        protocol = self._call_llm_api(prompt)
        
        # 4. è§£æå’Œè¿”å›ç»“æœ
        return {
            'query': query,
            'retrieved_context': retrieved_info,
            'generated_protocol': protocol,
            'evaluation_metrics': self._evaluate_protocol(protocol)
        }
    
    def _build_rag_context(self, retrieved_info: List[Dict]) -> str:
        """æ„å»ºRAGä¸Šä¸‹æ–‡"""
        context = "ç›¸å…³æ–‡çŒ®ä¿¡æ¯ï¼š\n"
        for i, info in enumerate(retrieved_info, 1):
            context += f"\n--- æ–‡çŒ® {i} (ç›¸ä¼¼åº¦: {info.get('similarity_score', 0):.3f}) ---\n"
            context += f"æ ‡é¢˜: {info.get('title', '')}\n"
            context += f"æ‘˜è¦: {info.get('summary', '')}\n"
            context += f"å‚¬åŒ–å‰‚: {info.get('catalyst', '')}\n"
            context += f"æº¶å‰‚: {info.get('solvent', '')}\n"
            context += f"ååº”æ¡ä»¶: {info.get('experimental_conditions', '')}\n"
        return context
    
    def _construct_protocol_prompt(self, query: str, context: str) -> str:
        """æ„å»ºåè®®ç”Ÿæˆæç¤º"""
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ–å­¦å®¶åŠ©æ‰‹ã€‚åŸºäºä»¥ä¸‹ç›¸å…³æ–‡çŒ®ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·çš„æŸ¥è¯¢è®¾è®¡è¯¦ç»†ã€å¯è¡Œçš„å®éªŒæ–¹æ¡ˆã€‚
        
        {context}
        
        ç”¨æˆ·æŸ¥è¯¢ï¼š{query}
        
        è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„è¯¦ç»†å®éªŒæ–¹æ¡ˆï¼š
        1. æ¨èçš„å‚¬åŒ–å‰‚åŠå…¶ç”¨é‡
        2. æº¶å‰‚é€‰æ‹©
        3. ååº”æ¡ä»¶ï¼ˆæ¸©åº¦ã€å‹åŠ›ã€æ—¶é—´ï¼‰
        4. å…·ä½“æ“ä½œæ­¥éª¤
        5. é¢„æœŸäº§ç‡å’Œé€‰æ‹©æ€§
        6. å®‰å…¨æ³¨æ„äº‹é¡¹
        7. æˆæœ¬å’Œç»æµæ€§è€ƒè™‘
        
        è¯·ç¡®ä¿æ–¹æ¡ˆå…·ä½“ã€å¯æ‰§è¡Œï¼Œå¹¶åŸºäºæä¾›çš„æ–‡çŒ®ä¿¡æ¯ã€‚
        """
        return prompt
    
    def _call_llm_api(self, prompt: str) -> str:
        """
        è°ƒç”¨LLM APIç”Ÿæˆå›å¤
        æ³¨æ„ï¼šè¿™é‡Œéœ€è¦æ ¹æ®å®é™…ä½¿ç”¨çš„LLMæœåŠ¡è¿›è¡Œå®ç°
        """
        # ç®€åŒ–å®ç° - å®é™…åº”è°ƒç”¨DeepSeek APIæˆ–å…¶ä»–LLMæœåŠ¡
        try:
            # ç¤ºä¾‹ï¼šä½¿ç”¨OpenAIæ ¼å¼çš„APIè°ƒç”¨
            response = openai.ChatCompletion.create(
                model="deepseek-chat",  # æˆ–å®é™…ä½¿ç”¨çš„æ¨¡å‹
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _parse_extracted_data(self, text: str) -> Dict[str, Any]:
        """è§£æLLMæå–çš„ç»“æ„åŒ–æ•°æ®"""
        # å®ç°æ–‡æœ¬åˆ°ç»“æ„åŒ–æ•°æ®çš„è§£æé€»è¾‘
        lines = text.split('\n')
        data = {}
        current_key = None
        
        for line in lines:
            if ':' in line:
                key, value = line.split(':', 1)
                data[key.strip()] = value.strip()
                current_key = key.strip()
            elif current_key and line.strip():
                data[current_key] += ' ' + line.strip()
        
        return data
    
    def _evaluate_protocol(self, protocol: str) -> Dict[str, float]:
        """è¯„ä¼°ç”Ÿæˆæ–¹æ¡ˆçš„è´¨é‡"""
        # ç®€åŒ–çš„è¯„ä¼°é€»è¾‘
        evaluation = {
            'feasibility_score': self._assess_feasibility(protocol),
            'safety_score': self._assess_safety(protocol),
            'cost_effectiveness_score': self._assess_cost_effectiveness(protocol),
            'green_chemistry_score': self._assess_green_chemistry(protocol)
        }
        return evaluation
    
    def _assess_feasibility(self, protocol: str) -> float:
        """è¯„ä¼°å¯è¡Œæ€§"""
        feasibility_keywords = ['æ˜ç¡®', 'å…·ä½“', 'å¯æ‰§è¡Œ', 'å·²éªŒè¯', 'æ–‡çŒ®æ”¯æŒ']
        score = 0.0
        for keyword in feasibility_keywords:
            if keyword in protocol:
                score += 0.2
        return min(score, 1.0)
    
    def _assess_safety(self, protocol: str) -> float:
        """è¯„ä¼°å®‰å…¨æ€§"""
        safety_keywords = ['å®‰å…¨', 'é˜²æŠ¤', 'é€šé£', 'å‹åŠ›', 'æ¸©åº¦æ§åˆ¶', 'æƒ°æ€§æ°”ä½“']
        score = 0.0
        for keyword in safety_keywords:
            if keyword in protocol:
                score += 0.15
        return min(score, 1.0)
    
    def _assess_cost_effectiveness(self, protocol: str) -> float:
        """è¯„ä¼°æˆæœ¬æ•ˆç›Š"""
        cost_keywords = ['å»‰ä»·', 'ç»æµ',å¯å›æ”¶', 'ä½æˆæœ¬', 'å·¥ä¸šçº§']
        score = 0.0
        for keyword in cost_keywords:
            if keyword in protocol:
                score += 0.2
        return min(score, 1.0)
    
    def _assess_green_chemistry(self, protocol: str) -> float:
        """è¯„ä¼°ç»¿è‰²åŒ–å­¦åŸåˆ™"""
        green_keywords = ['æ°´ç›¸', 'æ— æ¯’', 'å¯å›æ”¶', 'ç¯å¢ƒå‹å¥½', 'ç»¿è‰²æº¶å‰‚']
        score = 0.0
        for keyword in green_keywords:
            if keyword in protocol:
                score += 0.2
        return min(score, 1.0)
    
    def add_literature(self, pdf_path: str):
        """æ·»åŠ æ–°çš„æ–‡çŒ®åˆ°çŸ¥è¯†åº“"""
        text = self.extract_text_from_pdf(pdf_path)
        structured_data = self.structured_data_extraction(text)
        
        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        self.knowledge_base.append(structured_data)
        
        # æ›´æ–°å‘é‡æ•°æ®åº“
        self._build_vector_database()
        
        print(f"æˆåŠŸæ·»åŠ æ–‡çŒ®: {structured_data.get('title', 'æœªçŸ¥æ ‡é¢˜')}")

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # åˆå§‹åŒ–ç³»ç»Ÿ
    chem_ai = ChemReactSeek("chemical_knowledge_base.json")
    
    # æŸ¥è¯¢ç¤ºä¾‹
    query = "è®¾è®¡5-ç¾Ÿç”²åŸºç³ é†›(HMF)æ°¢åŒ–ç”Ÿæˆ2,5-äºŒç¾Ÿç”²åŸºå‘‹å–ƒçš„å®éªŒæ–¹æ¡ˆ"
    
    # ç”Ÿæˆååº”æ–¹æ¡ˆ
    result = chem_ai.generate_reaction_protocol(query)
    
    print("=== ç”Ÿæˆçš„å®éªŒæ–¹æ¡ˆ ===")
    print(result['generated_protocol'])
    print("\n=== è¯„ä¼°æŒ‡æ ‡ ===")
    for metric, score in result['evaluation_metrics'].items():
        print(f"{metric}: {score:.2f}")
    
    print("\n=== æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡çŒ® ===")
    for i, context in enumerate(result['retrieved_context'][:3], 1):
        print(f"{i}. {context.get('title', '')} (ç›¸ä¼¼åº¦: {context.get('similarity_score', 0):.3f})")

if __name__ == "__main__":
    main()
```

## ğŸ”§ é…å¥—å·¥å…·å’Œé…ç½®æ–‡ä»¶

### 1. çŸ¥è¯†åº“JSONç»“æ„ç¤ºä¾‹ (`chemical_knowledge_base.json`)
```json
[
    {
        "title": "Palladium-catalyzed hydrogenation of furan derivatives",
        "summary": "Study on selective hydrogenation of furanic compounds using Pd/C catalyst",
        "chemical_reaction": "HMF â†’ DHMF",
        "catalyst": "Pd/C (1-5 wt%)",
        "solvent": "methanol, ethanol, water",
        "experimental_conditions": "Temperature: 80-100Â°C, Pressure: 2-3 MPa, Time: 4-6 hours",
        "yield": "77%",
        "selectivity": "98%"
    }
]
```

### 2. ç¯å¢ƒä¾èµ– (`requirements.txt`)
```txt
faiss-cpu==1.7.4
torch==2.0.1
transformers==4.30.2
sentence-transformers==2.2.2
PyMuPDF==1.22.5
numpy==1.24.3
openai==0.27.8
```

## ğŸ’¡ é‡è¦è¯´æ˜

1. **LLM APIé›†æˆ**ï¼šéœ€è¦æ ¹æ®å®é™…ä½¿ç”¨çš„LLMæœåŠ¡ï¼ˆå¦‚DeepSeek APIï¼‰ä¿®æ”¹ `_call_llm_api` æ–¹æ³•
2. **å‘é‡æ•°æ®åº“**ï¼šå½“å‰ä½¿ç”¨FAISSï¼Œå¯æ ¹æ®éœ€è¦åˆ‡æ¢åˆ°å…¶ä»–å‘é‡æ•°æ®åº“
3. **çŸ¥è¯†åº“æ„å»º**ï¼šéœ€è¦é¢„å…ˆæ„å»ºåŒ–å­¦æ–‡çŒ®çŸ¥è¯†åº“
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šç”Ÿäº§ç¯å¢ƒéœ€è¦è€ƒè™‘ç¼“å­˜ã€æ‰¹å¤„ç†ç­‰ä¼˜åŒ–æªæ–½

è¿™ä¸ªå®ç°æä¾›äº†ChemReactSeekçš„æ ¸å¿ƒåŠŸèƒ½æ¡†æ¶ï¼Œå®é™…éƒ¨ç½²æ—¶éœ€è¦æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ã€‚
