ä»¥ä¸‹æ˜¯åœ¨ Linux ç³»ç»Ÿä¸‹å®‰è£…å’Œé…ç½®è¿è¡Œè¯¥ä¼˜åŒ–ç®—æ³•æ‰€éœ€ç¯å¢ƒçš„å®Œæ•´æŒ‡å—ã€‚

## ğŸ§ ç¯å¢ƒå®‰è£…å’Œé…ç½®

### 1. åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv spab_optimization
source spab_optimization/bin/activate

# å‡çº§pip
pip install --upgrade pip
```

### 2. å®‰è£…ä¾èµ–åŒ…
åˆ›å»º `requirements.txt` æ–‡ä»¶ï¼š
```txt
torch>=2.0.0
botorch>=0.9.0
gpytorch>=1.10.0
numpy>=1.21.0
scipy>=1.7.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
pandas>=1.3.0
seaborn>=0.11.0
jupyter>=1.0.0
tqdm>=4.62.0
```

å®‰è£…ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

### 3. éªŒè¯å®‰è£…
åˆ›å»ºéªŒè¯è„šæœ¬ `test_installation.py`ï¼š
```python
#!/usr/bin/env python3

import torch
import botorch
import gpytorch
import numpy as np
import sklearn

print("=== ç¯å¢ƒéªŒè¯ ===")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"BoTorchç‰ˆæœ¬: {botorch.__version__}")
print(f"GPyTorchç‰ˆæœ¬: {gpytorch.__version__}")
print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")

print("æ‰€æœ‰ä¾èµ–åŒ…å®‰è£…æˆåŠŸï¼")
```

è¿è¡ŒéªŒè¯ï¼š
```bash
python test_installation.py
```

### 4. å®Œæ•´çš„è¿è¡Œè„šæœ¬
åˆ›å»º `run_optimization.py`ï¼š
```python
#!/usr/bin/env python3
"""
RHPä¼˜åŒ–ç®—æ³•è¿è¡Œè„šæœ¬
ä½¿ç”¨æ–¹æ³•: python run_optimization.py --target [IFN|TNF] --algorithm [GA|BO|BOTH]
"""

import argparse
import numpy as np
import torch
import json
from datetime import datetime
import sys
import os

# æ·»åŠ è‡ªå®šä¹‰æ¨¡å—è·¯å¾„
sys.path.append('./src')

from optimization.ga import GeneticAlgorithm
from optimization.bo import BayesianOptimization

def setup_directories():
    """åˆ›å»ºç»“æœä¿å­˜ç›®å½•"""
    os.makedirs('results', exist_ok=True)
    os.makedirs('logs', exist_ok=True)
    os.makedirs('data/elisa', exist_ok=True)

def load_elisa_data(target_protein):
    """åŠ è½½ELISAå®éªŒæ•°æ®ï¼ˆç¤ºä¾‹ï¼‰"""
    # è¿™é‡Œåº”è¯¥æ›¿æ¢ä¸ºå®é™…çš„ELISAæ•°æ®åŠ è½½é€»è¾‘
    if target_protein.upper() == 'IFN':
        target_mean = 0.471  # æ ¹æ®è®ºæ–‡ä¸­çš„éšæœºé‡‡æ ·ç‚¹å¹³å‡å€¼
        control_mean = 0.630
    elif target_protein.upper() == 'TNF':
        target_mean = 1.0    # éœ€è¦æ ¹æ®å®é™…æ•°æ®è°ƒæ•´
        control_mean = 1.0
    else:
        raise ValueError("ç›®æ ‡è›‹ç™½å¿…é¡»æ˜¯ IFN æˆ– TNF")
    
    return target_mean, control_mean

def create_score_function(target_protein, target_mean, control_mean):
    """åˆ›å»ºè¯„åˆ†å‡½æ•°"""
    def score_function(composition):
        """
        åŸºäºELISAæ•°æ®çš„è¯„åˆ†å‡½æ•°
        composition: 8ç»´å‘é‡ï¼Œè¡¨ç¤ºRHPä¸­å„ç»„åˆ†æ‘©å°”åˆ†æ•°
        """
        # è¿™é‡Œåº”è¯¥æ›¿æ¢ä¸ºå®é™…çš„ELISAä¿¡å·é¢„æµ‹æ¨¡å‹
        # ç¤ºä¾‹ä½¿ç”¨éšæœºæ£®æ—æˆ–ç¥ç»ç½‘ç»œé¢„æµ‹ELISAä¿¡å·
        try:
            # æ¨¡æ‹ŸELISAä¿¡å·é¢„æµ‹
            target_signal = np.dot(composition, np.random.randn(8)) + 1.0
            control_signal = np.dot(composition, np.random.randn(8)) + 0.5
            
            # è®¡ç®—æ ‡å‡†åŒ–è¯„åˆ†
            score = (target_signal / target_mean) - (control_signal / control_mean)
            return float(score)
        except Exception as e:
            print(f"è¯„åˆ†è®¡ç®—é”™è¯¯: {e}")
            return -10.0  # è¿”å›æä½åˆ†
    
    return score_function

def save_results(algorithm, best_composition, best_score, target_protein, iteration):
    """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"results/{target_protein}_{algorithm}_{timestamp}.json"
    
    result = {
        'algorithm': algorithm,
        'target_protein': target_protein,
        'best_composition': best_composition.tolist() if hasattr(best_composition, 'tolist') else best_composition,
        'best_score': float(best_score),
        'timestamp': timestamp,
        'iteration': iteration
    }
    
    with open(filename, 'w') as f:
        json.dump(result, f, indent=2)
    
    print(f"ç»“æœå·²ä¿å­˜è‡³: {filename}")
    return filename

def main():
    parser = argparse.ArgumentParser(description='RHPä¼˜åŒ–ç®—æ³•')
    parser.add_argument('--target', type=str, required=True, choices=['IFN', 'TNF'], 
                       help='ç›®æ ‡è›‹ç™½: IFN æˆ– TNF')
    parser.add_argument('--algorithm', type=str, default='BOTH', 
                       choices=['GA', 'BO', 'BOTH'], help='ä¼˜åŒ–ç®—æ³•')
    parser.add_argument('--iterations', type=int, default=10, help='è¿­ä»£æ¬¡æ•°')
    parser.add_argument('--population', type=int, default=50, help='GAç§ç¾¤å¤§å°')
    parser.add_argument('--init_samples', type=int, default=10, help='BOåˆå§‹æ ·æœ¬æ•°')
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒ
    setup_directories()
    
    # åŠ è½½ELISAæ•°æ®
    target_mean, control_mean = load_elisa_data(args.target)
    score_function = create_score_function(args.target, target_mean, control_mean)
    
    print(f"å¼€å§‹ä¼˜åŒ–ç›®æ ‡è›‹ç™½: {args.target}")
    print(f"ä½¿ç”¨ç®—æ³•: {args.algorithm}")
    print(f"è¿­ä»£æ¬¡æ•°: {args.iterations}")
    
    results = {}
    
    # è¿è¡Œé—ä¼ ç®—æ³•
    if args.algorithm in ['GA', 'BOTH']:
        print("\n" + "="*50)
        print("è¿è¡Œé—ä¼ ç®—æ³•...")
        print("="*50)
        
        ga = GeneticAlgorithm(
            population_size=args.population,
            num_generations=args.iterations,
            mutation_rate=0.1
        )
        
        best_ga, score_ga = ga.run(score_function, num_components=8)
        results['GA'] = {'composition': best_ga, 'score': score_ga}
        
        save_results('GA', best_ga, score_ga, args.target, args.iterations)
    
    # è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
    if args.algorithm in ['BO', 'BOTH']:
        print("\n" + "="*50)
        print("è¿è¡Œè´å¶æ–¯ä¼˜åŒ–...")
        print("="*50)
        
        bo = BayesianOptimization(
            n_init=args.init_samples,
            n_iter=args.iterations,
            noise_var=0.12
        )
        
        best_bo, score_bo = bo.run(score_function, num_components=8)
        results['BO'] = {'composition': best_bo, 'score': score_bo}
        
        save_results('BO', best_bo, score_bo, args.target, args.iterations)
    
    # è¾“å‡ºæœ€ç»ˆç»“æœæ¯”è¾ƒ
    print("\n" + "="*50)
    print("ä¼˜åŒ–ç»“æœæ¯”è¾ƒ")
    print("="*50)
    
    for algo, result in results.items():
        print(f"{algo}:")
        print(f"  æœ€ä½³è¯„åˆ†: {result['score']:.4f}")
        print(f"  æœ€ä½³ç»„æˆ: {result['composition']}")
        print()

if __name__ == "__main__":
    main()
```

### 5. é¡¹ç›®ç›®å½•ç»“æ„
```bash
mkdir -p src/optimization data/elisa results logs

# åˆ›å»ºç›®å½•ç»“æ„
tree .
# .
# â”œâ”€â”€ run_optimization.py
# â”œâ”€â”€ requirements.txt
# â”œâ”€â”€ test_installation.py
# â”œâ”€â”€ src/
# â”‚   â””â”€â”€ optimization/
# â”‚       â”œâ”€â”€ __init__.py
# â”‚       â”œâ”€â”€ ga.py
# â”‚       â””â”€â”€ bo.py
# â”œâ”€â”€ data/
# â”‚   â””â”€â”€ elisa/
# â”œâ”€â”€ results/
# â””â”€â”€ logs/
```

### 6. æ¨¡å—åŒ–ä»£ç 
å°†ç®—æ³•ä»£ç åˆ†åˆ«ä¿å­˜åˆ°æ¨¡å—ä¸­ï¼š

**`src/optimization/ga.py`**:
```python
import numpy as np

class GeneticAlgorithm:
    # è¿™é‡Œæ”¾å…¥å‰é¢å®šä¹‰çš„ GeneticAlgorithm ç±»ä»£ç 
    pass
```

**`src/optimization/bo.py`**:
```python
import torch
import botorch
from botorch.models import SingleTaskGP
# è¿™é‡Œæ”¾å…¥å‰é¢å®šä¹‰çš„ BayesianOptimization ç±»ä»£ç 

class BayesianOptimization:
    pass
```

**`src/optimization/__init__.py`**:
```python
from .ga import GeneticAlgorithm
from .bo import BayesianOptimization

__all__ = ['GeneticAlgorithm', 'BayesianOptimization']
```

### 7. ä½¿ç”¨ç¤ºä¾‹
```bash
# æ¿€æ´»ç¯å¢ƒ
source spab_optimization/bin/activate

# è¿è¡Œä¼˜åŒ–ï¼ˆIFNç›®æ ‡è›‹ç™½ï¼Œä½¿ç”¨ä¸¤ç§ç®—æ³•ï¼‰
python run_optimization.py --target IFN --algorithm BOTH --iterations 10

# ä»…è¿è¡Œé—ä¼ ç®—æ³•
python run_optimization.py --target TNF --algorithm GA --population 100 --iterations 20

# ä»…è¿è¡Œè´å¶æ–¯ä¼˜åŒ–
python run_optimization.py --target IFN --algorithm BO --init_samples 20 --iterations 15
```

### 8. ç³»ç»Ÿç›‘æ§è„šæœ¬
åˆ›å»º `monitor_resources.sh`ï¼š
```bash
#!/bin/bash
# ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

echo "=== ç³»ç»Ÿèµ„æºç›‘æ§ ==="
echo "CPUä½¿ç”¨ç‡: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')%"
echo "å†…å­˜ä½¿ç”¨: $(free -h | grep Mem | awk '{print $3"/"$2}')"
echo "GPUä½¿ç”¨æƒ…å†µ:"
nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv
```

ç»™è„šæœ¬æ‰§è¡Œæƒé™ï¼š
```bash
chmod +x monitor_resources.sh
./monitor_resources.sh
```

### 9. ç¯å¢ƒå¯¼å‡º
```bash
# å¯¼å‡ºç¯å¢ƒé…ç½®
pip freeze > requirements_lock.txt

# åœ¨å…¶ä»–æœºå™¨ä¸Šæ¢å¤ç¯å¢ƒ
pip install -r requirements_lock.txt
```

ä»¥ä¸‹æ˜¯æ ¹æ®è®ºæ–‡ã€ŠData-Driven Design of Random Heteropolypeptides as Synthetic Polyclonal Antibodiesã€‹ä¸­â€œDesignâ€éƒ¨åˆ†æè¿°çš„å®Œæ•´ä»£ç å®ç°ï¼ŒåŒ…æ‹¬**é—ä¼ ç®—æ³•ï¼ˆGAï¼‰** å’Œ**è´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰** ä¸¤ç§ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºä» RHP ç»„åˆç©ºé—´ä¸­é«˜æ•ˆæœç´¢é«˜é€‰æ‹©æ€§ç»“åˆèƒ½åŠ›çš„åˆæˆå¤šå…‹éš†æŠ—ä½“ã€‚

---

## ğŸ§¬ å®Œæ•´ä»£ç å®ç°

```python
import numpy as np
import torch
import botorch
from botorch.models import SingleTaskGP
from botorch.fit import fit_gpytorch_model
from botorch.acquisition import qNoisyExpectedImprovement
from botorch.optim import optimize_acqf
from gpytorch.mlls import ExactMarginalLogLikelihood
from sklearn.preprocessing import normalize

# ================================
# é—ä¼ ç®—æ³•ï¼ˆGenetic Algorithmï¼‰
# ================================

class GeneticAlgorithm:
    def __init__(self, population_size, num_generations, mutation_rate=0.1):
        self.population_size = population_size
        self.num_generations = num_generations
        self.mutation_rate = mutation_rate

    def initialize_population(self, num_components=8):
        """åˆå§‹åŒ–ç§ç¾¤ï¼šæ¯ä¸ªä¸ªä½“æ˜¯ä¸€ä¸ª8ç»´å‘é‡ï¼Œè¡¨ç¤ºå„ç»„åˆ†æ‘©å°”åˆ†æ•°"""
        population = np.random.rand(self.population_size, num_components)
        return normalize(population, norm='l1', axis=1)

    def evaluate_fitness(self, population, score_function):
        """è¯„ä¼°ç§ç¾¤ä¸­æ¯ä¸ªä¸ªä½“çš„é€‚åº”åº¦ï¼ˆScoreï¼‰"""
        return np.array([score_function(ind) for ind in population])

    def select_parents(self, population, fitness, num_parents):
        """é€‰æ‹©é€‚åº”åº¦æœ€é«˜çš„ä¸ªä½“ä½œä¸ºçˆ¶ä»£"""
        indices = np.argsort(fitness)[-num_parents:]
        return population[indices]

    def crossover(self, parent1, parent2):
        """å•ç‚¹äº¤å‰"""
        point = np.random.randint(1, len(parent1))
        child = np.concatenate([parent1[:point], parent2[point:]])
        return child / np.sum(child)

    def mutate(self, individual):
        """é«˜æ–¯å™ªå£°çªå˜ + åŸºå› äº¤æ¢"""
        if np.random.rand() < self.mutation_rate:
            # å¯¹éé›¶åŸºå› æ·»åŠ é«˜æ–¯å™ªå£°
            mask = individual > 0
            noise = np.random.normal(0, 0.1, size=individual.shape)
            individual[mask] += noise[mask]
            individual = np.clip(individual, 0, 1)
            individual /= np.sum(individual)

            # éšæœºäº¤æ¢ä¸¤ä¸ªåŸºå› ä½ç½®
            idx1, idx2 = np.random.choice(len(individual), 2, replace=False)
            individual[idx1], individual[idx2] = individual[idx2], individual[idx1]

        return individual

    def run(self, score_function, num_components=8):
        """è¿è¡Œé—ä¼ ç®—æ³•"""
        population = self.initialize_population(num_components)
        best_individual = None
        best_fitness = -np.inf

        for gen in range(self.num_generations):
            fitness = self.evaluate_fitness(population, score_function)
            parents = self.select_parents(population, fitness, self.population_size // 2)

            # ç”Ÿæˆä¸‹ä¸€ä»£
            next_generation = []
            for _ in range(self.population_size):
                p1, p2 = parents[np.random.choice(len(parents), 2, replace=False)]
                child = self.crossover(p1, p2)
                child = self.mutate(child)
                next_generation.append(child)

            population = np.array(next_generation)

            # æ›´æ–°æœ€ä½³ä¸ªä½“
            current_best_fitness = np.max(fitness)
            if current_best_fitness > best_fitness:
                best_fitness = current_best_fitness
                best_individual = population[np.argmax(fitness)]

            print(f"Generation {gen+1}, Best Fitness: {best_fitness:.4f}")

        return best_individual, best_fitness


# ================================
# è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰
# ================================

class BayesianOptimization:
    def __init__(self, n_init=10, n_iter=30, noise_var=0.12):
        self.n_init = n_init
        self.n_iter = n_iter
        self.noise_var = noise_var
        self.X = None
        self.Y = None

    def initialize_data(self, score_function, num_components=8):
        """åˆå§‹åŒ–éšæœºæ ·æœ¬"""
        X = np.random.rand(self.n_init, num_components)
        X = normalize(X, norm='l1', axis=1)
        Y = np.array([score_function(x) for x in X]).reshape(-1, 1)
        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)

    def get_model(self, X, Y):
        """æ„å»ºé«˜æ–¯è¿‡ç¨‹ä»£ç†æ¨¡å‹"""
        model = SingleTaskGP(X, Y)
        mll = ExactMarginalLogLikelihood(model.likelihood, model)
        fit_gpytorch_model(mll)
        return model

    def optimize_acquisition(self, model, bounds, q=1):
        """ä½¿ç”¨ qNEI è·å–æ–°å€™é€‰ç‚¹"""
        acq_func = qNoisyExpectedImprovement(model, self.X, prune_baseline=True)
        candidates, _ = optimize_acqf(
            acq_func, bounds, q=q, num_restarts=20, raw_samples=512
        )
        return candidates

    def run(self, score_function, num_components=8):
        """è¿è¡Œè´å¶æ–¯ä¼˜åŒ–"""
        bounds = torch.tensor([[0.] * num_components, [1.] * num_components])
        self.X, self.Y = self.initialize_data(score_function, num_components)

        for i in range(self.n_iter):
            model = self.get_model(self.X, self.Y)
            candidates = self.optimize_acquisition(model, bounds, q=1)
            new_X = candidates.detach()
            new_Y = torch.tensor([score_function(x.numpy()) for x in new_X]).reshape(-1, 1)

            self.X = torch.cat([self.X, new_X])
            self.Y = torch.cat([self.Y, new_Y])

            print(f"BO Iteration {i+1}, Best Score: {self.Y.max().item():.4f}")

        best_idx = self.Y.argmax()
        return self.X[best_idx].numpy(), self.Y[best_idx].item()


# ================================
# ç¤ºä¾‹è¯„åˆ†å‡½æ•°ï¼ˆéœ€æ ¹æ®å®éªŒæ•°æ®è‡ªå®šä¹‰ï¼‰
# ================================

def example_score_function(composition):
    """
    è¾“å…¥ï¼š8ç»´å‘é‡ï¼Œè¡¨ç¤º RHP ä¸­å„ç»„åˆ†æ‘©å°”åˆ†æ•°
    è¾“å‡ºï¼šScore = Target/mean(Target) - Control/mean(Control)
    """
    # è¿™é‡Œåº”æ›¿æ¢ä¸ºå®é™…çš„ ELISA æ•°æ®æˆ–æ¨¡æ‹Ÿå‡½æ•°
    target_mean = 1.0  # åº”æ ¹æ®éšæœºé‡‡æ ·ç‚¹è®¡ç®—
    control_mean = 1.0
    target_signal = np.dot(composition, np.random.randn(8)) + 1.0
    control_signal = np.dot(composition, np.random.randn(8)) + 0.5
    score = target_signal / target_mean - control_signal / control_mean
    return score


# ================================
# ä¸»ç¨‹åºï¼šè¿è¡Œä¸¤ç§ä¼˜åŒ–ç®—æ³•
# ================================

if __name__ == "__main__":
    # é—ä¼ ç®—æ³•
    print("Running Genetic Algorithm...")
    ga = GeneticAlgorithm(population_size=50, num_generations=10)
    best_ga, score_ga = ga.run(example_score_function)
    print(f"GA Best: {best_ga}, Score: {score_ga:.4f}")

    # è´å¶æ–¯ä¼˜åŒ–
    print("\nRunning Bayesian Optimization...")
    bo = BayesianOptimization(n_init=10, n_iter=20)
    best_bo, score_bo = bo.run(example_score_function)
    print(f"BO Best: {best_bo}, Score: {score_bo:.4f}")
```

---

## ğŸ“Œ è¯´æ˜

- **é—ä¼ ç®—æ³•ï¼ˆGAï¼‰**ï¼š
  - åˆå§‹åŒ–ç§ç¾¤ â†’ é€‰æ‹©çˆ¶ä»£ â†’ äº¤å‰ â†’ çªå˜ â†’ è¯„ä¼°é€‚åº”åº¦ â†’ è¿­ä»£ä¼˜åŒ–ã€‚
  - é€‚åº”åº¦å‡½æ•°ä¸º `Score`ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–è¯¥å€¼ã€‚

- **è´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰**ï¼š
  - ä½¿ç”¨ `SingleTaskGP` ä½œä¸ºä»£ç†æ¨¡å‹ï¼Œ`qNoisyExpectedImprovement` ä½œä¸ºé‡‡é›†å‡½æ•°ã€‚
  - æ¯æ¬¡è¿­ä»£æå‡ºä¸€ä¸ªæ–°å€™é€‰ç‚¹ï¼Œæ›´æ–°æ¨¡å‹å¹¶ç»§ç»­ã€‚

- **è¯„åˆ†å‡½æ•°**ï¼š
  - æ­¤å¤„ä¸ºç¤ºä¾‹å‡½æ•°ï¼Œå®é™…åº”æ›¿æ¢ä¸ºåŸºäº ELISA å®éªŒæ•°æ®çš„çœŸå®è¯„åˆ†å‡½æ•°ã€‚

---

å¦‚æœéœ€è¦æˆ‘ä¸ºä½ **é€‚é…çœŸå®æ•°æ®æ¥å£**æˆ–**éƒ¨ç½²åˆ°è‡ªåŠ¨åŒ–å®éªŒå¹³å°**ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ çš„å…·ä½“æ•°æ®æ ¼å¼æˆ–ç³»ç»Ÿç¯å¢ƒã€‚
